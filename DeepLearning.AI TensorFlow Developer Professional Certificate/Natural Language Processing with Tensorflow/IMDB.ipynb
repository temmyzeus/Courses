{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHdIG0v50Tl6YmYDKDDV/P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/temmyzeus/Tensorflow-Courses/blob/master/DeepLearning.AI%20TensorFlow%20Developer%20Professional%20Certificate/Natural%20Language%20Processing%20with%20Tensorflow/IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnJFNOKy-F4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6b7803-407f-49e2-e2ad-433a05248222"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow_datasets as tfds\n",
        "print('Tensorflow Version: ', tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow Version:  2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKzp8ZdxBR8e"
      },
      "source": [
        "imdb, info = tfds.load(\n",
        "    name='imdb_reviews',\n",
        "    with_info=True,\n",
        "    as_supervised=True\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qBr1NzWPSD5"
      },
      "source": [
        "train_sentences = []\n",
        "train_labels = []\n",
        "\n",
        "test_sentences = []\n",
        "test_labels = []\n",
        "\n",
        "for sent, label in imdb.get('train'):\n",
        "    sent = sent.numpy().decode()\n",
        "    label = label.numpy()\n",
        "    train_sentences.append(sent)\n",
        "    train_labels.append(label)\n",
        "\n",
        "\n",
        "for sent, label in imdb.get('test'):\n",
        "    sent = sent.numpy().decode()\n",
        "    label = label.numpy()\n",
        "    test_sentences.append(sent)\n",
        "    test_labels.append(label)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2Vm7-mAVsvF"
      },
      "source": [
        "oov_token: str = '<UNK>'\n",
        "max_length: int = 120\n",
        "padding_type: str = 'post'\n",
        "trunc_type: str = 'post'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcN0t78ARPGQ"
      },
      "source": [
        "tokenizer = Tokenizer(\n",
        "    num_words=None,\n",
        "    oov_token=oov_token\n",
        ")\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcQyQJ_KS94h",
        "outputId": "28aa146c-bb00-40f7-f7a2-554ddc5395b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n: int = 4\n",
        "text = train_sentences[n]\n",
        "print('Original Sentence', text)\n",
        "print('Sequences', tokenizer.texts_to_sequences([text]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence As others have mentioned, all the women that go nude in this film are mostly absolutely gorgeous. The plot very ably shows the hypocrisy of the female libido. When men are around they want to be pursued, but when no \"men\" are around, they become the pursuers of a 14 year old boy. And the boy becomes a man really fast (we should all be so lucky at this age!). He then gets up the courage to pursue his true love.\n",
            "Sequences [[15, 406, 26, 1044, 30, 2, 370, 13, 138, 2513, 9, 12, 20, 24, 666, 425, 1485, 2, 112, 53, 10786, 285, 2, 11039, 5, 2, 667, 14362, 52, 347, 24, 185, 34, 179, 6, 28, 6986, 19, 52, 55, 347, 24, 185, 34, 411, 2, 23381, 5, 4, 2426, 289, 152, 428, 3, 2, 428, 458, 4, 130, 64, 700, 73, 142, 30, 28, 36, 2040, 31, 12, 556, 27, 93, 212, 54, 2, 3147, 6, 6628, 25, 281, 117]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yz_OIFXUxcw"
      },
      "source": [
        "train_padded = pad_sequences(\n",
        "    sequences=train_sequences,\n",
        "    maxlen=max_length,\n",
        "    padding='post',\n",
        "    truncating='post'\n",
        ")\n",
        "\n",
        "test_padded = train_padded = pad_sequences(\n",
        "    sequences=test_sequences,\n",
        "    maxlen=max_length,\n",
        "    padding=padding_type,\n",
        "    truncating=trunc_type\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjAJcxAfY08e"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3--qoDluY7iT"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}